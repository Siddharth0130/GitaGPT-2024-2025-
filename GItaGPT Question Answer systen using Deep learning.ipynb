{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "IEqxiqPronZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac0e399-4b66-4d34-8984-e829890b060c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/gita_project/\"\n",
        "os.makedirs(save_path, exist_ok=True)  # This will create the folder if it doesn't exist\n"
      ],
      "metadata": {
        "id": "dnqbz4QkpuaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vuja4EwZoid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94794141-6b78-4221-b126-329bb3b5169b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.2/259.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# === 1. Install dependencies ===\n",
        "!pip install -q streamlit streamlit-chat pyngrok faiss-cpu sentence-transformers cohere\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 2. Write model_script.py ===\n",
        "model_script = '''\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "import re\n",
        "import cohere\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "load_path = \"/content/drive/MyDrive/gita_project/\"\n",
        "index = faiss.read_index(load_path + \"gita_index.faiss\")\n",
        "\n",
        "with open(load_path + \"gita_texts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    texts = json.load(f)\n",
        "\n",
        "with open(load_path + \"gita_records.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    records = json.load(f)\n",
        "\n",
        "with open(load_path + \"chapter_summaries.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    chapter_summaries_raw = json.load(f)\n",
        "\n",
        "chapter_summaries = {int(k): v for k, v in chapter_summaries_raw.items()}\n",
        "id_map = {i: records[i] for i in range(len(records))}\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"j92ZwLSyxUJzU80UHBbldJ7gUVodVqkmYQaEcqjS\"\n",
        "co = cohere.Client(os.getenv(\"COHERE_API_KEY\"))\n",
        "\n",
        "def detect_query_type(query):\n",
        "    query = query.lower()\n",
        "    if any(kw in query for kw in [\"word meaning\", \"explain word\", \"शब्द\", \"शब्दार्थ\"]):\n",
        "        return \"word_meaning\"\n",
        "    elif any(kw in query for kw in [\"hindi\", \"अर्थ\", \"मतलब\", \"हिंदी\"]):\n",
        "        return \"hindi_meaning\"\n",
        "    elif any(kw in query for kw in [\"shloka\", \"sanskrit\", \"original\", \"श्लोक\"]):\n",
        "        return \"shloka\"\n",
        "    elif any(kw in query for kw in [\"summary\", \"message of chapter\", \"what is chapter\", \"explain chapter\"]):\n",
        "        return \"chapter_summary\"\n",
        "    elif any(kw in query for kw in [\"list chapters\", \"chapter names\", \"all chapters\", \"what are the chapters\", \"names of chapters\"]):\n",
        "        return \"list_chapters\"\n",
        "    else:\n",
        "        return \"english_meaning\"\n",
        "\n",
        "def extract_verse_reference(query):\n",
        "    match = re.search(r'(\\\\d+)\\\\.(\\\\d+)', query)\n",
        "    if match:\n",
        "        return f\"{match.group(1)}.{match.group(2)}\"\n",
        "    return None\n",
        "\n",
        "def extract_chapter_number(query):\n",
        "    match = re.search(r'(chapter|adhyaya)\\\\s*(\\\\d+)', query.lower())\n",
        "    if match:\n",
        "        return int(match.group(2))\n",
        "    return None\n",
        "\n",
        "def generate_final_answer(query, retrieved_text):\n",
        "    prompt = f\"\"\"You are a helpful assistant that answers questions based on the Bhagavad Gita.\n",
        "Answer the following user question using the retrieved text.\n",
        "\n",
        "User question: {query}\n",
        "\n",
        "Retrieved data:\n",
        "{retrieved_text}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    response = co.chat(\n",
        "        model=\"command-nightly\",\n",
        "        message=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1500\n",
        "    )\n",
        "    return response.text.strip()\n",
        "\n",
        "def search_verses(query, top_k=3):\n",
        "    query_type = detect_query_type(query)\n",
        "\n",
        "    if query_type == \"chapter_summary\":\n",
        "        chapter_num = extract_chapter_number(query)\n",
        "        if chapter_num and chapter_num in chapter_summaries:\n",
        "            summary_data = chapter_summaries[chapter_num]\n",
        "            title = summary_data.get(\"title\", f\"Chapter {chapter_num}\")\n",
        "            summary = summary_data.get(\"summary\", \"No summary available.\")\n",
        "            retrieved_text = f\"🕉️ **Chapter {chapter_num}: {title}**\\\\n📝 **Summary**: {summary}\"\n",
        "            return generate_final_answer(query, retrieved_text)\n",
        "        else:\n",
        "            return f\"❌ No summary found for chapter {chapter_num}.\"\n",
        "\n",
        "    verse_id = extract_verse_reference(query)\n",
        "\n",
        "    if query_type == \"list_chapters\":\n",
        "        chapter_lines = []\n",
        "        for chapter_num in sorted(chapter_summaries):\n",
        "            chapter = chapter_summaries[chapter_num]\n",
        "            title = chapter.get(\"title\", f\"Chapter {chapter_num}\")\n",
        "            chapter_lines.append(f\"{chapter_num}. {title}\")\n",
        "        retrieved_text = \"🕉️ **Chapters in the Bhagavad Gita**:\\\\n\\\\n\" + \"\\\\n\".join(chapter_lines)\n",
        "        return generate_final_answer(query, retrieved_text)\n",
        "\n",
        "    if verse_id:\n",
        "        results = [rec for rec in records if rec['id'] == verse_id]\n",
        "        if not results:\n",
        "            return f\"❌ No verse found for ID {verse_id}\"\n",
        "    else:\n",
        "        query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "        D, I = index.search(np.array(query_embedding), top_k)\n",
        "        results = [id_map[i] for i in I[0]]\n",
        "\n",
        "    output_blocks = []\n",
        "    for res in results:\n",
        "        vid = res['id']\n",
        "        context = res.get('context', '')\n",
        "        meta = res.get('metadata', {})\n",
        "        answer = meta.get(query_type) or \"❌ No data available for this query type.\"\n",
        "        shloka = meta.get(\"transliteration\", \"\")\n",
        "        eng = res.get(\"text\", \"\").split(\"Commentary\")[0].strip()\n",
        "        commentary = meta.get(\"commentary\", \"\")\n",
        "\n",
        "        block = f\"\"\"📖 **Verse:** {vid} ({context})\\\\n🕉️ **Shloka**: {shloka}\\\\n💬 **Answer**: {answer}\\\\n📘 **English Meaning**: {eng}\\\\n🧠 **Commentary**: {commentary}\"\"\"\n",
        "        output_blocks.append(block)\n",
        "\n",
        "    retrieved_text = \"\\\\n\\\\n\".join(output_blocks)\n",
        "    return generate_final_answer(query, retrieved_text)\n",
        "\n",
        "def gitasan_response(prompt):\n",
        "    answer = search_verses(prompt)\n",
        "    return answer\n",
        "'''\n",
        "\n",
        "with open(\"model_script.py\", \"w\") as f:\n",
        "    f.write(model_script)\n"
      ],
      "metadata": {
        "id": "PQzF15z0aJV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 3. Write app.py ===\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "from model_script import gitasan_response\n",
        "import base64\n",
        "\n",
        "# Set config\n",
        "st.set_page_config(page_title=\"🕉️ GitaSan: The Bhagavad Gita Assistant\", layout=\"centered\")\n",
        "\n",
        "# === Add background image ===\n",
        "def add_background(image_file):\n",
        "    with open(image_file, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    encoded = base64.b64encode(data).decode()\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "        [data-testid=\"stAppViewContainer\"] {{\n",
        "            background-image: url(\"data:image/png;base64,{encoded}\");\n",
        "            background-size: cover;\n",
        "            background-position: left top;\n",
        "            background-repeat: no-repeat;\n",
        "            background-attachment: fixed;\n",
        "        }}\n",
        "\n",
        "        [data-testid=\"stHeader\"] {{\n",
        "            background: rgba(0,0,0,0);\n",
        "        }}\n",
        "\n",
        "        [data-testid=\"stToolbar\"] {{\n",
        "            right: 2rem;\n",
        "        }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "add_background(\"krishna_bg.png\")  # <-- Make sure this file is in the same directory\n",
        "\n",
        "# === App content ===\n",
        "st.markdown(\"<h1 style='text-align: center; color: #FFFFFF;'>🕉️ GitaGPT</h1>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<p style='text-align: center; font-size: 18px;'>Your spiritual guide powered by the Bhagavad Gita ✨</p>\", unsafe_allow_html=True)\n",
        "\n",
        "with st.form(\"chat_form\", clear_on_submit=True):\n",
        "    prompt = st.text_input(\"Ask a question about the Bhagavad Gita\", \"\")\n",
        "    submitted = st.form_submit_button(\"Send\")\n",
        "\n",
        "if submitted and prompt:\n",
        "    with st.spinner(\"Meditating on your question... 🧘‍♂️\"):\n",
        "        response = gitasan_response(prompt)\n",
        "        st.markdown(\"### 🙋 You asked:\")\n",
        "        st.write(prompt)\n",
        "        st.markdown(\"### 🤖 GitaSan says:\")\n",
        "        st.write(response)\n",
        "\n",
        "st.markdown(\"<hr><center><sub>Made with ❤️ and devotion</sub></center>\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n"
      ],
      "metadata": {
        "id": "Tc_WJntiaOcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 4. Launch Streamlit with ngrok ===\n",
        "from pyngrok import ngrok\n",
        "import threading, time, os\n",
        "\n",
        "ngrok.kill()  # Clean up previous tunnels\n",
        "\n",
        "# Launch Streamlit app\n",
        "def run():\n",
        "    os.system(\"streamlit run app.py\")\n",
        "\n",
        "threading.Thread(target=run).start()\n",
        "time.sleep(5)\n",
        "\n",
        "# Add your Ngrok token (if not already saved)\n",
        "!ngrok config add-authtoken \"2vO1dUWb2d63hrSjzhoV3mdkYC0_5UrYk4aMxhFBbDbcPY7QF\"\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"🌐 Your GitaSan is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84_tAoRMaWaA",
        "outputId": "5a98d8f3-8671-4703-e980-fae7d1a2a5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "🌐 Your GitaSan is live at: NgrokTunnel: \"https://ab0a-104-196-43-90.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.open(\"krishna_bg.png\").format\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1WrXxxqBpkq1",
        "outputId": "db6e482f-cde9-416e-94cd-cc0aca1e6879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PNG'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}